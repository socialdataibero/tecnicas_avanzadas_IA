---
title: K-means
category:
  - ü§ñ ML
subcategory:
  - No supervisado
  - Clustering
tags:
  - Etiqueta1
  - Etiqueta2
  - Etiqueta3
status:
  - üîµ En Progreso
date: 2003-12-02
asigned_to:
  - "[[Armando]]"
---
--- 
# üìù Ficha T√©cnica: K-means

## ‚úÖ Estado de Compleci√≥n
- [x] **T√≠tulo del algoritmo**
- [x] **Representaci√≥n gr√°fica del algoritmo**
- [x] **Introducci√≥n al algoritmo y su relevancia**
- [x] **Bases Matem√°ticas del Algoritmo**
- [ ] **C√≥digo de ejemplo en Python**
- [ ] **Descripci√≥n de los tipos de datos aplicables**
- [ ] **Supuestos de los datos**
- [ ] **Ejemplos de aplicaci√≥n pr√°ctica**
- [ ] **Enlaces a recursos adicionales para profundizar en el tema**
- [ ] **Referencias**

---
## 1. T√≠tulo del Algoritmo

### **K-means**

---
## 2. Representaci√≥n Gr√°fica del Algoritmo

![[k_means_icon.png]]

Referencia: https://holypython.com/k-means/k-means-history/

---
## 3. Introducci√≥n al Algoritmo 

**K-means** es un algoritmo fundamental de aprendizaje autom√°tico no supervisado utilizado para agrupar datos en conjuntos distintos basados en similitudes de caracter√≠sticas. El objetivo principal es particionar un conjunto de datos en k cl√∫steres predefinidos, donde cada punto de datos pertenece al cl√∫ster con la media m√°s cercana, que act√∫a como el *centr√≥ide* del cl√∫ster.

Aspectos clave de K-means incluyen su eficiencia computacional, lo que lo hace adecuado para conjuntos de datos grandes, y su simplicidad en la implementaci√≥n. Sin embargo, presenta limitaciones como la necesidad de especificar el n√∫mero de cl√∫steres (k) por adelantado y la sensibilidad a la ubicaci√≥n inicial de los centr√≥ides, lo que puede afectar el resultado final del agrupamiento. Adem√°s, K-means asume que los cl√∫steres son esf√©ricos y de tama√±o igual, lo que puede no ser v√°lido para todos los conjuntos de datos.

K-means se aplica ampliamente en diversos dominios, incluyendo segmentaci√≥n de clientes, compresi√≥n de im√°genes y reconocimiento de patrones, debido a su capacidad para descubrir estructuras inherentes dentro de los datos. A pesar de su simplicidad, una consideraci√≥n cuidadosa de los m√©todos de inicializaci√≥n y los pasos de preprocesamiento, como el escalado de caracter√≠sticas, puede mejorar significativamente su rendimiento y fiabilidad.

---
## 4. Bases Matem√°ticas del Algoritmo

Las bases matem√°ticas del algoritmo K-means se centran en la partici√≥n √≥ptima de un conjunto de datos en **k** cl√∫steres, minimizando la variabilidad intra-cl√∫ster. El objetivo principal es minimizar la **suma de las distancias cuadr√°ticas** entre los puntos de datos y sus respectivos centr√≥ides. Esto se expresa mediante la funci√≥n objetivo:

$$
J = \sum_{i=1}^{k} \sum_{x \in C_i} \|x - \mu_i\|^2
$$

donde:

- $k$ es el n√∫mero de cl√∫steres.
- $C_i$ es el conjunto de puntos asignados al cl√∫ster $i$.
- $\mu_i$ es el centr√≥ide del cl√∫ster $i$.
- $\|x - \mu_i\|$ representa la distancia Euclidiana entre el punto $x$ y el centr√≥ide $\mu_i$.

El algoritmo K-means sigue un enfoque iterativo conocido como **algoritmo de Lloyd**:

1. **Inicializaci√≥n**: Selecci√≥n de $k$ centr√≥ides iniciales, a menudo de forma aleatoria.
2. **Asignaci√≥n**: Cada punto $x$ se asigna al cl√∫ster cuyo centr√≥ide $\mu_i$ minimiza $\|x - \mu_i\|^2$.
3. **Actualizaci√≥n**: Recalcular cada centr√≥ide $\mu_i$ como la media de todos los puntos asignados al cl√∫ster $i$:

   $$
   \mu_i = \frac{1}{|C_i|} \sum_{x \in C_i} x
   $$

4. **Convergencia**: Repetir los pasos de asignaci√≥n y actualizaci√≥n hasta que los centr√≥ides ya no cambien significativamente o se alcance un n√∫mero m√°ximo de iteraciones.

Matem√°ticamente, K-means busca una soluci√≥n de optimizaci√≥n no convexa, por lo que puede converger a un m√≠nimo local dependiendo de la inicializaci√≥n. La elecci√≥n de la m√©trica de distancia y la normalizaci√≥n de los datos tambi√©n son aspectos cruciales que afectan el rendimiento y la exactitud del algoritmo.


### 4.1 Ilustraci√≥n del funcionamiento (*Opcional*)

![[k_means_des.png]]

**Referencia:** https://www.analyticsvidhya.com/blog/2020/10/a-simple-explanation-of-k-means-clustering/

---
## 5. C√≥digo de Ejemplo en Python

 >**Instrucciones**: Incluir un bloque de c√≥digo funcional en Python que ilustre la implementaci√≥n b√°sica del algoritmo. Aseg√∫rese de que el c√≥digo est√© bien documentado.

```python
# Code example in Python

def code_exaple()
	pass
````

---
## 6.  Tipos de Datos

>*Instrucciones:* Detallar los tipos de datos con los que el algoritmo trabaja mejor (por ejemplo, datos tabulares, series de tiempo, im√°genes, texto, etc.). Indique tambi√©n si requiere preprocesamiento de datos espec√≠fico.

- Tipo 1
- Tipo 2

---
## 7.  Supuestos de los datos

>*Instrucciones:* Para aplicar los algoritmos, muchas veces los datos requieren cumplir ciertas condiciones. En caso de ser as√≠, listarlos. 

- Supuesto 1
- Supuesto 2
--- 
## 8. Ejemplos de Aplicaci√≥n

> *Instrucciones:* Presentar uno o m√°s ejemplos de problemas reales en los que se haya utilizado el algoritmo con √©xito. Pueden incluirse ejemplos t√≠picos de aplicaci√≥n del algoritmo.

- Ejemplo 1
- Ejemplo 2
---
## 9. Recursos Adicionales

> *Instrucciones:* Proporcionar enlaces a art√≠culos, libros, cursos o tutoriales que permitan profundizar en el estudio del algoritmo.

- [enlace 1](https://www.ibm.com/topics/support-vector-machine#:~:text=A%20support%20vector%20machine%20(SVM,in%20an%20N%2Ddimensional%20space.)
---
## 10. Referencias

- Referencia 1
- Referencia 2