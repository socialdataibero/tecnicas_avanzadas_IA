---
title: Arboles_Decision
category:
  - ü§ñ ML
subcategory:
  - Supervisado
  - Clasificacion
  - Regresion
tags:
  - Etiqueta1
  - Etiqueta2
  - Etiqueta3
status:
  - üîµ En Progreso
date: 2003-12-31
asigned_to:
  - "[[Armando]]"
---
--- 
# üìù Ficha T√©cnica: Arboles_Decision

## ‚úÖ Estado de Compleci√≥n
- [x] **T√≠tulo del algoritmo**
- [x] **Representaci√≥n gr√°fica del algoritmo**
- [x] **Introducci√≥n al algoritmo y su relevancia**
- [x] **Bases Matem√°ticas del Algoritmo**
- [ ] **C√≥digo de ejemplo en Python**
- [ ] **Descripci√≥n de los tipos de datos aplicables**
- [ ] **Supuestos de los datos**
- [ ] **Ejemplos de aplicaci√≥n pr√°ctica**
- [ ] **Enlaces a recursos adicionales para profundizar en el tema**
- [x] **Referencias**

---
## 1. T√≠tulo del Algoritmo

### **√Årboles de Decisi√≥n**

---
## 2. Representaci√≥n Gr√°fica del Algoritmo

![[decision_tree_icon.png]]
*Referencia:* <a href="https://www.flaticon.com/free-icons/decision-tree" title="decision tree icons">Decision tree icons created by Freepik - Flaticon</a> 

---
## 3. Introducci√≥n al Algoritmo 

Los **√°rboles de decisi√≥n** son uno de los m√©todos m√°s populares del *machine learning* para construir modelos de **regresi√≥n** y **clasificaci√≥n** a trav√©s de algoritmos estructurados jer√°rquicamente de tipo √°rbol. El funcionamiento de estas t√©cnicas se basa modelar decisiones y sus posibles consecuencias como una estructura de √°rbol, donde cada nodo interno representa una decisi√≥n basada en una caracter√≠stica espec√≠fica (evaluaci√≥n condicional), cada rama denota el resultado de esa decisi√≥n, y cada nodo hoja corresponde a una predicci√≥n final o etiqueta de clase. El proceso comienza en el nodo ra√≠z y recorre el √°rbol tomando decisiones en cada nodo hasta llegar a una hoja *(Asst. Professor, Department of Computer Science, King Khalid University, Abha, Kingdom of Saudi Arabia. et al., 2023; Li, 2024)*.

Una de las principales ventajas de los √°rboles de decisi√≥n es su simplicidad e interpretabilidad, adem√°s de manejar datos tanto num√©ricos como categ√≥ricos y de requerir un preprocesamiento m√≠nimo de los datos. Sin embargo, una de sus desventajas m√°s importantes es su propensi√≥n al sobreajuste, (especialmente con √°rboles complejos), lo que puede reducir su capacidad de generalizaci√≥n en datos no vistos. Ante esto, existen t√©cnicas como la poda, establecer una profundidad m√°xima del √°rbol y m√©todos de ensamblaje como Random Forests y Gradient Boosting suelen emplearse para mejorar su robustez y precisi√≥n *(Rodionov & Mukhitdinova, 2023; Shanthamallu et al., n.d.)*.

---
## 4. Bases Matem√°ticas del Algoritmo

Los √°rboles de decisi√≥n se construyen mediante la partici√≥n recursiva del espacio de caracter√≠sticas para modelar decisiones y resultados. Matem√°ticamente, el proceso comienza seleccionando la mejor caracter√≠stica y umbral para dividir los datos en cada nodo, optimizando un criterio como:

- **Entrop√≠a** para clasificaci√≥n:
  $$
  H(S) = -\sum_{i} p_i \log p_i
  $$
- **Ganancia de informaci√≥n**:
  $$
  IG(S, A) = H(S) - \sum_{v} \frac{|S_v|}{|S|} H(S_v)
  $$
- **Impureza de Gini**:
  $$
  G(S) = 1 - \sum_{i} p_i^2
  $$

Algoritmos m√°s sofisticados como CART (*√Årboles de Clasificaci√≥n y Regresi√≥n*, por sus siglas en ingl√©s) utilizan estas medidas para realizar divisiones binarias recursivas y voraces. El √°rbol crece minimizando la impureza en cada paso:
$$
\text{Divisi√≥n} = \arg\min_{\text{caracter√≠stica, umbral}} \text{Impureza}
$$

Para prevenir el sobreajuste, se aplican t√©cnicas de poda, a menudo minimizando una funci√≥n de complejidad de costo:
$$
C(T) = C(T') + \alpha |T'|
$$
donde $C(T')$ es el error del sub√°rbol $T'$ y $\alpha$ es un par√°metro de regularizaci√≥n.

El modelo final equilibra el sesgo y la varianza, asegurando la generalizaci√≥n mediante la selecci√≥n de una estructura √≥ptima del √°rbol a trav√©s de m√©todos como la validaci√≥n cruzada. 

Referencias: *(Adam et al., 2024; Li, 2024; Shanthamallu et al., n.d.)*
### 4.1 Ilustraci√≥n del funcionamiento 

![[decision_trees_des.png]]

**Referencia:** https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/ 

---
## 5. C√≥digo de Ejemplo en Python

 >**Instrucciones**: Incluir un bloque de c√≥digo funcional en Python que ilustre la implementaci√≥n b√°sica del algoritmo. Aseg√∫rese de que el c√≥digo est√© bien documentado.

```python
# Code example in Python

def code_exaple()
	pass
````

---
## 6.  Tipos de Datos

>*Instrucciones:* Detallar los tipos de datos con los que el algoritmo trabaja mejor (por ejemplo, datos tabulares, series de tiempo, im√°genes, texto, etc.). Indique tambi√©n si requiere preprocesamiento de datos espec√≠fico.

- Tipo 1
- Tipo 2

---
## 7.  Supuestos de los datos

>*Instrucciones:* Para aplicar los algoritmos, muchas veces los datos requieren cumplir ciertas condiciones. En caso de ser as√≠, listarlos. 

- Supuesto 1
- Supuesto 2
--- 
## 8. Ejemplos de Aplicaci√≥n

> *Instrucciones:* Presentar uno o m√°s ejemplos de problemas reales en los que se haya utilizado el algoritmo con √©xito. Pueden incluirse ejemplos t√≠picos de aplicaci√≥n del algoritmo.

- Ejemplo 1
- Ejemplo 2
---
## 9. Recursos Adicionales

> *Instrucciones:* Proporcionar enlaces a art√≠culos, libros, cursos o tutoriales que permitan profundizar en el estudio del algoritmo.

- [enlace 1](https://www.ibm.com/topics/support-vector-machine#:~:text=A%20support%20vector%20machine%20(SVM,in%20an%20N%2Ddimensional%20space.)
---
## 10. Referencias

Adam, Timo, Marius √ñtting, y Rouven Michels. ¬´Markov-Switching Decision Trees¬ª. _AStA Advances in Statistical Analysis_ 108, n.o 2 (junio de 2024): 461-76. [https://doi.org/10.1007/s10182-024-00501-6](https://doi.org/10.1007/s10182-024-00501-6).

Asst. Professor, Department of Computer Science, King Khalid University, Abha, Kingdom of Saudi Arabia., Dr. Nirmla Sharma, Sameera Iqbal Muhmmad Iqbal, y Department of Computer Science, King Khalid University, Abha, Kingdom of Saudi Arabia. ¬´Applying Decision Tree Algorithm Classification and Regression Tree (CART) Algorithm to Gini Techniques Binary Splits¬ª. _International Journal of Engineering and Advanced Technology_ 12, n.o 5 (30 de junio de 2023): 77-81. [https://doi.org/10.35940/ijeat.E4195.0612523](https://doi.org/10.35940/ijeat.E4195.0612523).

Li, Hang. _Machine Learning Methods_. Singapore: Springer Nature Singapore, 2024. [https://doi.org/10.1007/978-981-99-3917-6](https://doi.org/10.1007/978-981-99-3917-6).

Rodionov, Andrei, y Munavvarkhan Mukhitdinova. ¬´THE ROLE OF A DECISION TREE AS A METHOD OF ARTIFICIAL INTELLIGENCE FOR THE ANALYSIS OF BIG DATA PROBLEMS¬ª. _Economics and Innovative Technologies_ 11, n.o 2 (28 de abril de 2023): 400-407. [https://doi.org/10.55439/EIT/vol11_iss2/i39](https://doi.org/10.55439/EIT/vol11_iss2/i39).

Shanthamallu, Uday Shankar, Andreas Spanias, Khalid Sayood, Kenichi Kanatani, Nasser Kehtarnavaz, Abhishek Sehgal, Shane Parris, y Arian Azarang. _Machine and Deep Learning Algorithms and Applications_, s.¬†f.