---
title: Bosque_Aleatorio
category:
  - ü§ñ ML
subcategory:
  - Supervisado
  - Regresion
  - Clasificacion
tags:
  - Etiqueta1
  - Etiqueta2
  - Etiqueta3
status:
  - üîµ En Progreso
date: 2003-11-30
asigned_to:
  - "[[Armando]]"
---
--- 
# üìù Ficha T√©cnica: Bosque_Aleatorio

## ‚úÖ Estado de Compleci√≥n
- [x] **T√≠tulo del algoritmo**
- [x] **Representaci√≥n gr√°fica del algoritmo**
- [x] **Introducci√≥n al algoritmo y su relevancia**
- [x] **Bases Matem√°ticas del Algoritmo**
- [ ] **C√≥digo de ejemplo en Python**
- [ ] **Descripci√≥n de los tipos de datos aplicables**
- [ ] **Supuestos de los datos**
- [ ] **Ejemplos de aplicaci√≥n pr√°ctica**
- [ ] **Enlaces a recursos adicionales para profundizar en el tema**
- [ ] **Referencias**

---
## 1. T√≠tulo del Algoritmo

### **Bosques Aleatorios (*Random Forest*)**

---
## 2. Representaci√≥n Gr√°fica del Algoritmo

![[random_forest_icon.png]]

Referencia: https://thenounproject.com/icon/random-forest-1503830/ 

---
## 3. Introducci√≥n al Algoritmo 

Random Forest es un algoritmo de aprendizaje autom√°tico poderoso y vers√°til que pertenece a la familia del aprendizaje en conjunto. Desarrollado por Leo Breiman y Adele Cutler, construye m√∫ltiples √°rboles de decisi√≥n durante el entrenamiento y produce la moda de sus clasificaciones o la predicci√≥n promedio para tareas de regresi√≥n. Al aprovechar la t√©cnica de bagging (agregaci√≥n bootstrap), Random Forest reduce la varianza y mitiga el sobreajuste, mejorando la generalizaci√≥n del modelo. 

Cada √°rbol en el bosque se entrena con un subconjunto aleatorio de los datos y un subconjunto aleatorio de caracter√≠sticas, promoviendo la diversidad entre los √°rboles y aumentando la robustez. Este m√©todo sobresale en el manejo de grandes conjuntos de datos con alta dimensionalidad y puede gestionar eficazmente tanto variables num√©ricas como categ√≥ricas. Adem√°s, Random Forest proporciona informaci√≥n valiosa sobre la importancia de las caracter√≠sticas, ayudando en la selecci√≥n e interpretaci√≥n de las mismas. Son resistentes al ruido y capaces de capturar relaciones no lineales complejas. 

Debido a su facilidad de uso, escalabilidad y alto rendimiento en diversos dominios‚Äîdesde finanzas y salud hasta an√°lisis de im√°genes y textos‚ÄîRandom Forest se ha convertido en un elemento b√°sico en el conjunto de herramientas de aprendizaje autom√°tico. Su capacidad para ofrecer predicciones precisas con una m√≠nima configuraci√≥n de hiperpar√°metros lo hace especialmente atractivo tanto para principiantes como para profesionales experimentados.


---
## 4. Bases Matem√°ticas del Algoritmo

Las bases matem√°ticas del algoritmo Random Forest se sustentan en el aprendizaje en conjunto, espec√≠ficamente mediante la t√©cnica de bagging (agregaci√≥n bootstrap). Matem√°ticamente, se generan m√∫ltiples √°rboles de decisi√≥n $T_1, T_2, \cdots, T_n$, donde cada √°rbol $T_i$ se entrena sobre una muestra de datos obtenida mediante remuestreo con reemplazo de los datos originales \( D \). Para cada divisi√≥n en un √°rbol, se selecciona aleatoriamente un subconjunto de caracter√≠sticas \( m \) de las \( p \) disponibles, lo que introduce diversidad entre los √°rboles y reduce la correlaci√≥n entre ellos.

La predicci√≥n final para clasificaci√≥n se obtiene mediante la moda de las predicciones individuales:
$$
\hat{y} = \text{mode}\{T_1(x), T_2(x), \ldots, T_n(x)\}
$$
Para regresi√≥n, se calcula el promedio:
$$
\hat{y} = \frac{1}{n} \sum_{i=1}^{n} T_i(x)
$$
La reducci√≥n de la varianza se logra al promediar m√∫ltiples √°rboles, lo que minimiza el sobreajuste caracter√≠stico de los √°rboles individuales. Las medidas de impureza, como el √≠ndice de Gini o la entrop√≠a, se utilizan para determinar las mejores divisiones en cada nodo. Adem√°s, el c√°lculo de la importancia de las variables se realiza evaluando la disminuci√≥n de impureza o el incremento en el error fuera de la muestra al permutar cada caracter√≠stica.

El algoritmo Random Forest optimiza la precisi√≥n y robustez del modelo mediante la combinaci√≥n de diversidad y agregaci√≥n, aprovechando principios estad√≠sticos y probabil√≠sticos para manejar alta dimensionalidad y complejidad en los datos.

### 4.1 Ilustraci√≥n del funcionamiento 

![[random_forest_des.png]]

**Referencia:** https://anasbrital98.github.io/blog/2021/Random-Forest/ 

---
## 5. C√≥digo de Ejemplo en Python

 >**Instrucciones**: Incluir un bloque de c√≥digo funcional en Python que ilustre la implementaci√≥n b√°sica del algoritmo. Aseg√∫rese de que el c√≥digo est√© bien documentado.

```python
# Code example in Python

def code_exaple()
	pass
````

---
## 6.  Tipos de Datos

>*Instrucciones:* Detallar los tipos de datos con los que el algoritmo trabaja mejor (por ejemplo, datos tabulares, series de tiempo, im√°genes, texto, etc.). Indique tambi√©n si requiere preprocesamiento de datos espec√≠fico.

- Tipo 1
- Tipo 2

---
## 7.  Supuestos de los datos

>*Instrucciones:* Para aplicar los algoritmos, muchas veces los datos requieren cumplir ciertas condiciones. En caso de ser as√≠, listarlos. 

- Supuesto 1
- Supuesto 2
--- 
## 8. Ejemplos de Aplicaci√≥n

> *Instrucciones:* Presentar uno o m√°s ejemplos de problemas reales en los que se haya utilizado el algoritmo con √©xito. Pueden incluirse ejemplos t√≠picos de aplicaci√≥n del algoritmo.

- Ejemplo 1
- Ejemplo 2
---
## 9. Recursos Adicionales

> *Instrucciones:* Proporcionar enlaces a art√≠culos, libros, cursos o tutoriales que permitan profundizar en el estudio del algoritmo.

- [enlace 1](https://www.ibm.com/topics/support-vector-machine#:~:text=A%20support%20vector%20machine%20(SVM,in%20an%20N%2Ddimensional%20space.)
---
## 10. Referencias

- Referencia 1
- Referencia 2