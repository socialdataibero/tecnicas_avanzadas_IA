---
title: CNN
category:
  - üß† DL
subcategory:
  - CV
tags:
  - Etiqueta1
  - Etiqueta2
  - Etiqueta3
status:
  - üîµ En Progreso
date: 19_11_2024
asigned_to:
  - "[[Armando]]"
---
--- 
# üìù Ficha T√©cnica: CNN

## ‚úÖ Estado de Compleci√≥n
- [x] **T√≠tulo del algoritmo**
- [x] **Representaci√≥n gr√°fica del algoritmo**
- [x] **Introducci√≥n al algoritmo y su relevancia**
- [x] **Bases Matem√°ticas del Algoritmo**
- [ ] **C√≥digo de ejemplo en Python**
- [ ] **Descripci√≥n de los tipos de datos aplicables**
- [ ] **Supuestos de los datos**
- [ ] **Ejemplos de aplicaci√≥n pr√°ctica**
- [ ] **Enlaces a recursos adicionales para profundizar en el tema**
- [ ] **Referencias**

---
## 1. T√≠tulo del Algoritmo

###  **Redes Neuronales Convolucionales *(CNN)*** 

---
## 2. Representaci√≥n Gr√°fica del Algoritmo

![[cnn_icon.png]]

Referencia: <a href="https://www.flaticon.es/iconos-gratis/vision-de-maquina" title="vision-de-maquina iconos">Vision-de-maquina iconos creados por Freepik - Flaticon</a> 

---
## 3. Introducci√≥n al Algoritmo 

Una **Red Neuronal Convolucional** (*CNN*, por sus siglas en ingl√©s) son un tipo de modelo del aprendizaje profundo, las cuales est√°n dise√±adas para procesar datos con **estructura matriciales**. Deben su nombre, debido a que su arquitectura se compone principalmente de **capas convolucionales** que aplican filtros (o **kernels**) para extraer caracter√≠sticas locales. Otro rasgo relevante de la arquitectura son las **capas de pooling**, las cuales reducen las dimensiones espaciales, optimizando el rendimiento y mitigando el sobreajuste. 

*Los conceptos fundamentales de este tipo de redes, incluyen el campo receptivo, que determina el √°rea de entrada que influye en una neurona espec√≠fica, y los par√°metros de stride y padding, que controlan el desplazamiento y el relleno de los filtros durante la convoluci√≥n. Los kernels son esenciales para detectar patrones como bordes y texturas, aprendidos autom√°ticamente durante el entrenamiento.

Las CNNs han revolucionado campos como la visi√≥n por computadora, permitiendo aplicaciones en **reconocimiento de im√°genes**, **detecci√≥n de objetos**, y **an√°lisis de video**, entre otros. Sus ventajas principales son la extracci√≥n autom√°tica de caracter√≠sticas, la eficiencia computacional mediante el compartimiento de par√°metros y la capacidad de escalar a entradas de alta dimensi√≥n. Sin embargo, enfrentan desaf√≠os como la necesidad de grandes vol√∫menes de datos y la interpretabilidad de sus decisiones. 

---
## 4. Bases Matem√°ticas del Algoritmo

 En el coraz√≥n funcional y matem√°tico de una CNN es la **operaci√≥n de convoluci√≥n**, la cual aplica un filtro sobre la entrada para generar **mapas de caracter√≠sticas**. Matem√°ticamente, esta operaci√≥n se expresa como:

$$
(I * K)(i, j) = \sum_{m=1}^{M} \sum_{n=1}^{N} I(i+m, j+n) \cdot K(m, n)
$$

Para introducir no linealidad y permitir la modelaci√≥n de relaciones complejas, se utilizan **funciones de activaci√≥n** como la ReLU, definida por:

$$
\text{ReLU}(x) = \max(0, x)
$$

Durante el entrenamiento, se emplea una **funci√≥n de p√©rdida** que mide la discrepancia entre las predicciones de la red y las etiquetas reales. Una com√∫n es la entrop√≠a cruzada:

$$
L = -\sum_{c=1}^{C} y_c \log(\hat{y}_c)
$$

El proceso de **backpropagation** calcula los gradientes necesarios para ajustar los pesos de la red, utilizando la f√≥rmula:

$$
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial w}
$$

Posteriormente, se optimizan los pesos mediante el m√©todo de **Descenso de Gradiente Estoc√°stico (SGD)**:

$$
w := w - \eta \frac{\partial L}{\partial w}
$$

Para evitar el sobreajuste, se aplica la **regularizaci√≥n por Dropout**, que desactiva aleatoriamente neuronas durante el entrenamiento:

$$
\text{Dropout}(x) = 
\begin{cases}
0 & \text{con probabilidad } p \\
\frac{x}{1-p} & \text{de otro modo}
\end{cases}
$$


### 4.1 Ilustraci√≥n del funcionamiento (*Opcional*)

![[cnn_des.png]]

**Referencia:** https://www.analytixlabs.co.in/blog/convolutional-neural-network/

---
## 5. C√≥digo de Ejemplo en Python

 >**Instrucciones**: Incluir un bloque de c√≥digo funcional en Python que ilustre la implementaci√≥n b√°sica del algoritmo. Aseg√∫rese de que el c√≥digo est√© bien documentado.

```python
# Code example in Python

def code_exaple()
	pass
````

---
## 6.  Tipos de Datos

>*Instrucciones:* Detallar los tipos de datos con los que el algoritmo trabaja mejor (por ejemplo, datos tabulares, series de tiempo, im√°genes, texto, etc.). Indique tambi√©n si requiere preprocesamiento de datos espec√≠fico.

- Tipo 1
- Tipo 2

---
## 7.  Supuestos de los datos

>*Instrucciones:* Para aplicar los algoritmos, muchas veces los datos requieren cumplir ciertas condiciones. En caso de ser as√≠, listarlos. 

- Supuesto 1
- Supuesto 2
--- 
## 8. Ejemplos de Aplicaci√≥n

> *Instrucciones:* Presentar uno o m√°s ejemplos de problemas reales en los que se haya utilizado el algoritmo con √©xito. Pueden incluirse ejemplos t√≠picos de aplicaci√≥n del algoritmo.

- Ejemplo 1
- Ejemplo 2
---
## 9. Recursos Adicionales

> *Instrucciones:* Proporcionar enlaces a art√≠culos, libros, cursos o tutoriales que permitan profundizar en el estudio del algoritmo.

- [enlace 1](https://www.ibm.com/topics/support-vector-machine#:~:text=A%20support%20vector%20machine%20(SVM,in%20an%20N%2Ddimensional%20space.)
---
## 10. Referencias

- Referencia 1
- Referencia 2